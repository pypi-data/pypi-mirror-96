Metadata-Version: 2.1
Name: simpletokenizer
Version: 0.1.2
Summary: A small example package
Home-page: https://github.com/tdd-ai/simple-tokenizer/
Author: Ali Safaya
Author-email: alisafaya@gmail.com
License: UNKNOWN
Download-URL: https://github.com/tdd-ai/simple-tokenizer/archive/v0.1.2.tar.gz
Platform: UNKNOWN
Classifier: Topic :: Text Processing
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Requires-Python: >=3.6
Description-Content-Type: text/markdown

# simple-tokenizer

An example of developing services as a python package

## Installation

```shell
pip install simpletokenizer
```

## Usage

```python
>>> import simpletokenizer
>>> simpletokenizer.tokenize("the fox jumps over the lazy dog")
['the', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog']
>>> simpletokenizer.count_tokens("the fox jumps over the lazy dog")
7
>>> simpletokenizer.get_unique_words("the fox jumps over the lazy dog")
['fox', 'jumps', 'over', 'the', 'dog', 'lazy']
```

