# -*- coding: utf-8 -*-
from setuptools import setup

packages = \
['nautobot_capacity_metrics',
 'nautobot_capacity_metrics.api',
 'nautobot_capacity_metrics.management',
 'nautobot_capacity_metrics.management.commands',
 'nautobot_capacity_metrics.tests']

package_data = \
{'': ['*']}

install_requires = \
['nautobot']

setup_kwargs = {
    'name': 'nautobot-capacity-metrics',
    'version': '1.0.0',
    'description': 'Plugin to improve the instrumentation of Nautobot and expose additional metrics (Application Metrics, RQ Worker).',
    'long_description': '# nautobot-plugin-capacity-metrics\n\nA plugin for [Nautobot](https://github.com/nautobot/nautobot) to expose additional metrics information.\n\nThe plugin is composed of multiple features that can be used independently:\n- Application Metrics Endpoint: prometheus endpoint at `/api/plugins/capacity-metrics/app-metrics`\n- RQ Queue Metrics Endpoint: prometheus endpoint at `/api/plugins/capacity-metrics/rq-metrics`\n- RQ Worker Metrics Command: Add prometheus endpoint on each RQ worker\n\n# Application Metrics Endpoint\n\nNautobot already exposes some information via a Prometheus endpoint but the information currently available are mostly at the system level and not at the application level.\n- **SYSTEM Metrics** are very useful to instrument code, track ephemeral information and get a better visibility into what is happening. (Example of metrics: nbr of requests, requests per second, nbr of exceptions, response time, etc ...) The idea is that when multiple instances of Nautobot are running behind a load balancer each one will produce a different set of metrics and the monitoring system needs to collect these metrics from all running instances and aggregate them in a dashboard. Nautobot exposes some system metrics at `localhost/metrics` [Nautobot DOC](https://nautobot.readthedocs.io/en/stable/additional-features/prometheus-metrics/).\n- **APPLICATION Metrics** are at a higher level and represent information that is the same across all instances of an application running behind a load balancer. If I have 3 instances of Nautobot running, there is no point to ask each of them how many Device objects I have in the database, since they will always return the same information. In this case, the goal is to expose only 1 endpoint that can be served by any running instance.\n\nSystem metrics and application level metrics are complementary with each other\n\nCurrently the plugin exposes these simple metrics by default:\n- RQ Queues stats\n- Jobs stats\n- Models count (configurable via configuration.py)\n\n# Queue System Metrics Endpoint\n\nIn addition to the default Nautobot system metrics which are exposed at `/metrics` which are largely centered around the Django system on which Nautobot is based this plugin provides some additional system metrics around the queuing system Nuatobot uses to communicate with the Nautobot worker services.  This endpoint is provided separately via `/api/plugins/capacity-metrics/rq-metrics`, this endpoint can be scraped more frequently than the other application metrics endpoint.\n## Add your own metrics\n\nThis plugin supports some options to generate and publish your own application metrics behind the same endpoint.\n\n### Option 1 - Register function(s) via configuration.py.\n\nIt\'s possible to create your own function to generate some metrics and register it to the plugin in the configuration.py.\nHere is an example where the custom function are centralized in a `metrics.py` file, located next to the main `configuration.py`.\n\n```python\n# metrics.py\nfrom prometheus_client.core import GaugeMetricFamily\n\ndef metric_prefix_utilization():\n    """Report prefix utilization as a metric per container."""\n    from ipam.models import Prefix  # pylint: disable=import-outside-toplevel\n\n    containers = Prefix.objects.filter(status="container").all()\n    g = GaugeMetricFamily(\n        "nautobot_prefix_utilization", "percentage of utilization per container prefix", labels=["prefix", "role", "site"]\n    )\n\n    for container in containers:\n\n        site = "none"\n        role = "none"\n        if container.role:\n            role = container.role.slug\n\n        if container.site:\n            site = container.site.slug\n\n        g.add_metric(\n            [str(container.prefix), site, role], container.get_utilization(),\n        )\n\n    yield g\n```\nThe new function can be imported in the `configuration.py` file and registered with the plugin.\n```python\n# configuration.py\nfrom nautobot.metrics import metric_prefix_utilization\nPLUGINS_CONFIG = {\n    "nautobot_capacity_metrics": {\n      "app_metrics": {\n        "extras": [\n          metric_prefix_utilization\n        ]\n      }\n    }\n},\n```\n\n### Option 2 - Registry for third party plugins\n\nAny plugin can include its own metrics to improve the visibility and/or the troubleshooting of the plugin itself.\nThird party plugins can register their own function(s) using the `ready()` function as part of their PluginConfig class.\n\n```python\n# my_plugin/__init__.py\nfrom nautobot_capacity_metrics import register_metric_func\nfrom nautobot.metrics import metric_circuit_bandwidth\n\nclass MyPluginConfig(PluginConfig):\n    name = "nautobot_myplugin"\n    verbose_name = "Demo Plugin "\n    # [ ... ]\n    def ready(self):\n        super().ready()\n        register_metric_func(metric_circuit_bandwidth)\n```\n\n### Option 3 - NOT AVAILABLE YET - Metrics directory\n\nIn the future it will be possible to add metrics by adding them in a predefined directory, similar to jobs.\n\n## Parameters\n\nThe behavior of the app_metrics feature can be controlled with the following list of settings (under `nautobot_capacity_metrics > app_metrics`):\n- `jobs` boolean (default True), publish stats about the jobs (success, warning, info, failure)\n- `queues` boolean (default True), publish stats about RQ Worker (nbr of worker, nbr and type of job in the different queues)\n- `models` nested dict, publish the count for a given object (Nbr Device, Nbr IP etc.. ). The first level must be the name of the module in lowercase (dcim, ipam etc..), the second level must be the name of the object (usually starting with a uppercase)\n    ```python\n    {\n      "dcim": {"Site": True, "Rack": True, "Device": True,},\n      "ipam": {"IPAddress": True, "Prefix": True}\n    }\n    ```\n## Usage\n\nConfigure your Prometheus server to collect the application metrics at `/api/plugins/capacity-metrics/app-metrics/`\n\n```yaml\n# Sample prometheus configuration\nscrape_configs:\n  - job_name: \'nautobot_app\'\n    scrape_interval: 120s\n    metrics_path: /api/plugins/capacity-metrics/app-metrics\n    static_configs:\n      - targets: [\'nautobot\']\n  - job_name: \'nautobot_queue\'\n    scrape_interval: 20s\n    metrics_path: /api/plugins/capacity-metrics/rq-metrics\n    static_configs:\n      - targets: [\'nautobot\']\n```\n\n# RQ Worker Metrics Endpoint\n\nThis plugin add a new django management command `rqworker_metrics` that is behaving identically to the default `rqworker` command except that this command also exposes a prometheus endpoint (default port 8001).\n\nWith this endpoint it become possible to instrument the tasks running asyncronously in the worker.\n\n## Usage\n\nThe new command needs to be executed on the worker as a replacement for the default `rqworker`\n```\nnautobot-server rqworker_metrics\n```\n\nThe port used to expose the prometheus endpoint can be configured for each worker in CLI.\n```\nnautobot-server rqworker_metrics --prom-port 8002\n```\n\nSince the rq-worker is based on a fork model, for this feature to work it\'\'s required to use prometheus in multi processes mode.\nTo enable this mode the environment variable `prometheus_multiproc_dir` must be define and point at a valid directory.\n\n# Installation\n\nThe plugin is available as a Python package in pypi and can be installed with pip\n```shell\npip install nautobot-plugin-capacity-metrics\n```\n\n> The plugin is compatible with Nautobot 2.8.1 and higher\n\nTo ensure Application Metrics Plugin is automatically re-installed during future upgrades, create a file named `local_requirements.txt` (if not already existing) in the Nautobot root directory (alongside `requirements.txt`) and list the `nautobot-plugin-capacity-metrics` package:\n\n```no-highlight\n# echo nautobot-plugin-capacity-metrics >> local_requirements.txt\n```\n\nOnce installed, the plugin needs to be enabled in your `configuration.py`\n```python\n# In your configuration.py\nPLUGINS = ["nautobot_capacity_metrics"]\n\n# PLUGINS_CONFIG = {\n#   "nautobot_capacity_metrics": {\n#     "app_metrics": {\n#       "models": {\n#         "dcim": {"Site": True, "Rack": True, "Device": True,},\n#          "ipam": {"IPAddress": True, "Prefix": True},\n#        },\n#        "jobs": True,\n#        "queues": True,\n#       }\n#     }\n#   }\n# }\n```\n\n## Included Grafana Dashboard\n\nIncluded within this plugin is a Grafana dashboard which will work with the example configuration above. To install this dashboard import the JSON from [Grafana Dashboard](nautobot_grafana_dashboard.json) into Grafana.\n\n![Nautobot Grafana Dashboard](nautobot_grafana_dashboard.png)\n\n# Contributing\n\nPull requests are welcomed and automatically built and tested against multiple version of Python and multiple version of Nautobot through TravisCI.\n\nThe project is packaged with a light development environment based on `docker-compose` to help with the local development of the project and to run the tests within TravisCI.\n\nThe project is following Network to Code software development guideline and is leveraging:\n- Black, Pylint, Bandit and pydocstyle for Python linting and formatting.\n- Django unit test to ensure the plugin is working properly.\n\n### CLI Helper Commands\n\nThe project is coming with a CLI helper based on [invoke](http://www.pyinvoke.org/) to help setup the development environment. The commands are listed below in 3 categories `dev environment`, `utility` and `testing`.\n\nEach command can be executed with `invoke <command>`. All commands support the arguments `--nautobot-ver` and `--python-ver` if you want to manually define the version of Python and Nautobot to use. Each command also has its own help `invoke <command> --help`\n\n#### Local dev environment\n```\n  build            Build all docker images.\n  debug            Start Nautobot and its dependencies in debug mode.\n  destroy          Destroy all containers and volumes.\n  start            Start Nautobot and its dependencies in detached mode.\n  stop             Stop Nautobot and its dependencies.\n```\n\n#### Utility\n```\n  cli              Launch a bash shell inside the running Nautobot container.\n  create-user      Create a new user in django (default: admin), will prompt for password.\n  makemigrations   Run Make Migration in Django.\n  nbshell          Launch a nbshell session.\n```\n#### Testing\n\n```\n  tests            Run all tests for this plugin.\n  pylint           Run pylint code analysis.\n  pydocstyle       Run pydocstyle to validate docstring formatting adheres to NTC defined standards.\n  bandit           Run bandit to validate basic static code security analysis.\n  black            Run black to check that Python files adhere to its style standards.\n  unittest         Run Django unit tests for the plugin.\n```\n\n## Questions\n\nFor any questions or comments, please check the [FAQ](FAQ.md) first and feel free to swing by the [Network to Code slack channel](https://networktocode.slack.com/) (channel #networktocode).\nSign up [here](http://slack.networktocode.com/)\n\n## Default Metrics for the application metrics endpoint\n\nThe following metrics will be provided via the `/api/plugins/capacity-metrics/app-metrics` endpoint:\n\n```\n# HELP nautobot_job_task_stats Per Job task statistics\n# TYPE nautobot_job_task_stats gauge\nnautobot_job_task_stats{module="local/users/CheckUser",name="total",status="success"} 1.0\nnautobot_job_task_stats{module="local/users/CheckUser",name="total",status="warning"} 0.0\nnautobot_job_task_stats{module="local/users/CheckUser",name="total",status="failure"} 0.0\nnautobot_job_task_stats{module="local/users/CheckUser",name="total",status="info"} 0.0\nnautobot_job_task_stats{module="local/users/CheckUser",name="test_is_uppercase",status="success"} 1.0\nnautobot_job_task_stats{module="local/users/CheckUser",name="test_is_uppercase",status="warning"} 0.0\nnautobot_job_task_stats{module="local/users/CheckUser",name="test_is_uppercase",status="failure"} 0.0\nnautobot_job_task_stats{module="local/users/CheckUser",name="test_is_uppercase",status="info"} 0.0\n# HELP nautobot_job_execution_status Job completion status\n# TYPE nautobot_job_execution_status gauge\nnautobot_job_execution_status{module="local/users/CheckUser",status="pending"} 0.0\nnautobot_job_execution_status{module="local/users/CheckUser",status="running"} 0.0\nnautobot_job_execution_status{module="local/users/CheckUser",status="completed"} 1.0\nnautobot_job_execution_status{module="local/users/CheckUser",status="errored"} 0.0\nnautobot_job_execution_status{module="local/users/CheckUser",status="failed"} 0.0\n# HELP nautobot_model_count Per Nautobot Model count\n# TYPE nautobot_model_count gauge\nnautobot_model_count{app="dcim",name="Site"} 24.0\nnautobot_model_count{app="dcim",name="Rack"} 24.0\nnautobot_model_count{app="dcim",name="Device"} 46.0\nnautobot_model_count{app="ipam",name="IPAddress"} 58.0\nnautobot_model_count{app="ipam",name="Prefix"} 18.0\n# HELP nautobot_app_metrics_processing_ms Time in ms to generate the app metrics endpoint\n# TYPE nautobot_app_metrics_processing_ms gauge\nnautobot_app_metrics_processing_ms 59.48257\n```\n\nThe following metrics will be provided via the `/api/plugins/capacity-metrics/rq-metrics` endpoint:\n\n```\n# HELP nautobot_queue_number_jobs Number of Job per RQ queue and status\n# TYPE nautobot_queue_number_jobs gauge\nnautobot_queue_number_jobs{name="check_releases",status="finished"} 0.0\nnautobot_queue_number_jobs{name="check_releases",status="started"} 0.0\nnautobot_queue_number_jobs{name="check_releases",status="deferred"} 0.0\nnautobot_queue_number_jobs{name="check_releases",status="failed"} 0.0\nnautobot_queue_number_jobs{name="check_releases",status="scheduled"} 0.0\nnautobot_queue_number_jobs{name="default",status="finished"} 0.0\nnautobot_queue_number_jobs{name="default",status="started"} 0.0\nnautobot_queue_number_jobs{name="default",status="deferred"} 0.0\nnautobot_queue_number_jobs{name="default",status="failed"} 0.0\nnautobot_queue_number_jobs{name="default",status="scheduled"} 0.0\n# HELP nautobot_queue_number_workers Number of worker per queue\n# TYPE nautobot_queue_number_workers gauge\nnautobot_queue_number_workers{name="check_releases"} 0.0\nnautobot_queue_number_workers{name="default"} 2.0\n# HELP nautobot_rq_metrics_processing_ms Time in ms to generate the app metrics endpoint\n# TYPE nautobot_rq_metrics_processing_ms gauge\nnautobot_rq_metrics_processing_ms 33.34308\n```',
    'author': 'Network to Code, LLC',
    'author_email': 'opensource@networktocode.com',
    'maintainer': None,
    'maintainer_email': None,
    'url': 'https://github.com/networktocode/nautobot-plugin-capacity-metrics',
    'packages': packages,
    'package_data': package_data,
    'install_requires': install_requires,
    'python_requires': '>=3.6,<4.0',
}


setup(**setup_kwargs)
