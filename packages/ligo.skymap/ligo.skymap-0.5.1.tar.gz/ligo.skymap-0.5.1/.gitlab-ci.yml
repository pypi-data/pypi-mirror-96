variables:
  LIGO_SKYMAP_USE_SYSTEM_CHEALPIX: 1
  OMP_NUM_THREADS: 4

include:
  - project: computing/gitlab-ci-templates
    file: python/lint.yml
  - project: computing/gitlab-ci-templates
    file: cluster/ssh.yml

stages:
  - deps
  - dist
  - test
  - deploy

#
# Read all requirements for the package and all extras from setup.cfg.
#

requirements:
  stage: deps
  image: python:slim
  script:
    - |
      python >requirements.txt <<EOF
      from configparser import ConfigParser
      conf = ConfigParser()
      conf.read('setup.cfg')
      print(conf['options']['install_requires'] + ''.join(conf['options.extras_require'].values()))
      EOF
  artifacts:
    paths:
      - requirements.txt
    expire_in: 1 day

#
# Build Python source package.
#

sdist:
  image: python
  stage: dist
  script:
    - pip install pep517
    - python -m pep517.build -s -o . .
  needs: []
  artifacts:
    paths:
      - '*.tar.*'
    expire_in: 1 day

#
# Build binary wheels for Linux and macOS.
#

wheel/manylinux:
  # This container is derived from the official manylinux image provided by
  # python.org (see PEP 513), and includes all of the LALSuite
  # build-dependencies.
  image: containers.ligo.org/lscsoft/lalsuite-manylinux/manylinux2014_x86_64:icc
  stage: dist
  script:
    # Build and install LALSuite
    - PYPREFIX=/opt/python/cp36-cp36m
    - ${PYPREFIX}/bin/pip install pep517
    - ${PYPREFIX}/bin/python -m pep517.build -b .
    - auditwheel repair dist/*.whl
    - rm dist/*
    - mv wheelhouse/* .
    - echo ARTIFACTS_URL=\"$CI_JOB_URL/artifacts/download\" > dotenv
  needs: []
  artifacts:
    reports:
      dotenv: dotenv
    paths:
      - '*.whl'
    expire_in: 1 day

wheel/macosx:
  variables:
    CC: gcc-mp-8
    CXX: g++-mp-8
  tags:
    - macos_sierra
  stage: dist
  script:
    - PYVERS=3.7
    # Enter virtualenv so that we have a controlled version of Numpy
    - python${PYVERS} -m venv env
    - source env/bin/activate
    - pip install pep517
    # FIXME: https://github.com/matthew-brett/delocate/pull/38
    - pip install git+https://github.com/lpsinger/delocate@namespace-packages#egg=delocate
    # Build and audit wheel
    - python -m pep517.build -b .
    - delocate-wheel -v -w wheelhouse dist/*.whl
    - rm -f *.whl
    - mv wheelhouse/* .
  needs: []
  artifacts:
    paths:
      - '*.whl'
    expire_in: 1 day

#
# Build Docker containers for dependencies listed in requirements.txt,
# plus dependencies for running the unit tests, collecting coverage data,
# and generating the docs.
#

.in-tmpdir: &in-tmpdir
  before_script:
    - WORKING_DIRECTORY="$(mktemp -d)"
    - cd "${WORKING_DIRECTORY}"
  after_script:
    - cd "${CI_PROJECT_DIR}"
    - rm -rf "${WORKING_DIRECTORY}"

.dependencies: &dependencies
  stage: dist
  variables:
    IMAGE_TAG: $CI_REGISTRY_IMAGE/$CI_JOB_NAME:$CI_COMMIT_REF_SLUG
    GIT_STRATEGY: none
  script:
    - docker login -u gitlab-ci-token -p $CI_JOB_TOKEN $CI_REGISTRY
    - |
      cat <<EOF > Dockerfile
      FROM python:${CI_JOB_NAME#*python}
      RUN apt-get update && apt-get -y install --no-install-recommends libchealpix-dev libgsl-dev pkg-config && rm -rf /var/lib/apt/lists/*
      RUN pip --no-cache-dir install pytest-cov gcovr pycobertura flake8 coverage tox
      COPY requirements.txt .
      RUN pip --no-cache-dir install -r requirements.txt && rm -f requirements.txt
      EOF
    - docker build -t $IMAGE_TAG .
    - docker push $IMAGE_TAG
  needs:
    - requirements

dependencies/python3.7:
  <<: *dependencies

dependencies/python3.8:
  <<: *dependencies

dependencies/python3.9:
  <<: *dependencies

#
# Generate documentation.
#

docs:
  image: $CI_REGISTRY_IMAGE/dependencies/python3.7:$CI_COMMIT_REF_SLUG
  stage: test
  <<: *in-tmpdir
  script:
    - tar --strip-components 1 -xf ${CI_PROJECT_DIR}/*.tar.*
    - tox -e build_docs
    - mv docs/_build/html ${CI_PROJECT_DIR}/
  needs:
    - dependencies/python3.7
    - sdist
  artifacts:
    paths:
      - html/
    expire_in: 1 day

#
# Test the wheels.
#

.test: &test
  <<: *in-tmpdir
  stage: test
  script:
    - pip install ${CI_PROJECT_DIR}/*.whl astroquery
    - python -c 'import sys; from ligo.skymap import test; sys.exit(test(args="--doctest-plus --doctest-ufunc --mpl --omp-get-num-threads --durations=10"))'

test/python3.7:
  <<: *test
  image: $CI_REGISTRY_IMAGE/dependencies/python3.7:$CI_COMMIT_REF_SLUG
  needs:
    - dependencies/python3.7
    - wheel/manylinux

test/python3.8:
  <<: *test
  image: $CI_REGISTRY_IMAGE/dependencies/python3.8:$CI_COMMIT_REF_SLUG
  needs:
    - dependencies/python3.8
    - wheel/manylinux

test/python3.9:
  <<: *test
  image: $CI_REGISTRY_IMAGE/dependencies/python3.9:$CI_COMMIT_REF_SLUG
  needs:
    - dependencies/python3.9
    - wheel/manylinux

#
# Measure test coverage:
# - coverage.py for Python code
# - gcov/gcovr for C code
#
# Export the results from both to Cobertura format because it's an XML format
# that both coverage.py and gcovr can write, merge them by hand, and then
# write HTML and text summaries.
#
# This would be a lot prettier if we could use coveralls or codecov.io,
# which support multilingual test coverage. However, those products don't
# integrate with git.ligo.org (or at least, they don't integrate for free).
#

test/coverage:
  stage: test
  image: $CI_REGISTRY_IMAGE/dependencies/python3.7:$CI_COMMIT_REF_SLUG
  variables:
    # -UNDEBUG
    #     enable C assertions
    # -coverage
    #     instrument C code for coverage measurement
    # -fsanitize=undefined
    #     enable GCC UndefinedBehaviorSanitizer
    # -fopenmp
    #     The -coverage breaks OpenMP detection in extension-helpers.
    #     See https://github.com/astropy/extension-helpers/issues/1
    CFLAGS: -UNDEBUG -coverage -fsanitize=undefined -fopenmp
  coverage: '/^TOTAL\s+.*\s+(\d+\.?\d*)%/'
  <<: *in-tmpdir
  script:
    - tar --strip-components 1 -xf ${CI_PROJECT_DIR}/*.tar.*
    # Run tests.
    - pip install -ve .[test]
    - pytest --capture=sys --doctest-plus --doctest-ufunc --mpl --durations=10 --cov ligo/skymap --junit-xml=${CI_PROJECT_DIR}/junit.xml
    # Write coverage reports in Cobertura format.
    - gcovr build/temp*/src -r . -x -o c-coverage.xml
    - coverage xml -o py-coverage.xml
    # Merge coverage reports.
    - ${CI_PROJECT_DIR}/.gitlab/combine-coverage.py py-coverage.xml c-coverage.xml coverage.xml
    # Write human-readable report.
    - pycobertura show coverage.xml -f html -o coverage.html
    - pycobertura show coverage.xml
    - cp coverage.html coverage.xml ${CI_PROJECT_DIR}
  needs:
    - dependencies/python3.7
    - sdist
  artifacts:
    paths:
      - coverage.html
    reports:
      cobertura: coverage.xml
      junit: junit.xml
    expire_in: 1 day

#
# Run flake8 linter to enforce code style.
#

lint:
  extends:
    - .python:flake8
  image: $CI_REGISTRY_IMAGE/dependencies/python3.7:$CI_COMMIT_REF_SLUG
  stage: test
  needs:
    - dependencies/python3.7

#
# Acceptance tests.
#

tests/review:
  stage: test
  extends: .ssh
  when: manual
  needs:
    - wheel/manylinux
  variables:
    GIT_STRATEGY: none
    REMOTE_HOST: skymap.testing@ldas-grid.ligo.caltech.edu
  script:
    - echo -e "section_start:`date +%s`:remote_clone\r\e[0KCloning HTCondor workflow on cluster"
    - gsissh -T $REMOTE_HOST "mkdir -p public_html && git clone --depth=1 --recurse-submodules --shallow-submodules https://git.ligo.org/leo-singer/ligo-skymap-acceptance-tests-public public_html/$CI_PIPELINE_ID"
    - echo -e "section_end:`date +%s`:remote_clone\r\e[0K"

    - echo -e "section_start:`date +%s`:remote_install\r\e[0KIntalling Python packages on cluster"
    - gsiscp *.whl $REMOTE_HOST:public_html/$CI_PIPELINE_ID
    - |
      gsissh -T $REMOTE_HOST "bash -e" <<EOF
      cd public_html/$CI_PIPELINE_ID
      /cvmfs/oasis.opensciencegrid.org/ligo/sw/conda/bin/python -m venv env
      source env/bin/activate
      pip install --upgrade pip wheel
      pip install *.whl
      pip install -r requirements.txt
      EOF
    - echo -e "section_end:`date +%s`:remote_install\r\e[0K"

    - echo -e "section_start:`date +%s`:remote_submit\r\e[0KRunning HTCondor workflow on cluster"
    - |
      gsissh -T $REMOTE_HOST "bash -e" <<EOF
      cd public_html/$CI_PIPELINE_ID
      source env/bin/activate
      condor_submit_dag -append accounting_group_user=leo.singer -batch-name pipeline/$CI_PIPELINE_ID htcondor/acceptance-tests.dag
      tail --follow=descriptor --retry htcondor/acceptance-tests.dag.dagman.out &
      condor_wait htcondor/acceptance-tests.dag.dagman.log
      kill %
      EOF
    - echo -e "section_end:`date +%s`:remote_submit\r\e[0K"

    - echo -e "section_start:`date +%s`:remote_retrieve\r\e[0KRetrieving artifacts from cluster"
    - gsiscp -r $REMOTE_HOST:public_html/$CI_PIPELINE_ID/site site
    - echo -e "section_end:`date +%s`:remote_retrieve\r\e[0K"

    - echo -e "section_start:`date +%s`:remote_cleanup\r\e[0KCleaning up files on cluster"
    - gsissh -T $REMOTE_HOST "rm -rf public_html/$CI_PIPELINE_ID"
    - echo -e "section_end:`date +%s`:remote_cleanup\r\e[0K"

  artifacts:
    paths:
      - site
      - site/index.html
    expose_as: acceptance tests
    expire_in: 1 week

#
# Gather coverage reports and docs for GitLab pages and build badges.
#

pages:
  stage: deploy
  script:
    - mv html public
    - mv coverage.html public/coverage.html
  needs:
    - docs
    - test/coverage
  artifacts:
    paths:
      - public
    expire_in: 30 days
  only:
    - master

#
# Upload to PyPI.
#

deploy/pypi:
  stage: deploy
  image: python:slim
  script:
    # TWINE_USERNAME and TWINE_PASSWORD are provided by CI secret variables
    - pip install twine
    - twine upload *.whl *.tar.*
  needs:
    - sdist
    - wheel/manylinux
    - wheel/macosx
  only:
    - tags
