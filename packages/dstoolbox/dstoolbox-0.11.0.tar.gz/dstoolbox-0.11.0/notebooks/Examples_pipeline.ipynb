{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using dstoolbox pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [PipelineY](#PipelineY)\n",
    "2. [SliceMixin](#SliceMixin)\n",
    "3. [DictFeatureUnion](#DictFeatureUnion)\n",
    "4. [DataFrameFeatureUnion](#DataFrameFeatureUnion)\n",
    "5. [TimedPipeline](#TimedPipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dstoolbox.pipeline import PipelineY\n",
    "from dstoolbox.pipeline import SliceMixin\n",
    "from dstoolbox.pipeline import DictFeatureUnion\n",
    "from dstoolbox.pipeline import DataFrameFeatureUnion\n",
    "from dstoolbox.pipeline import TimedPipeline\n",
    "from dstoolbox.transformers import ItemSelector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PipelineY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A variant of sklearn Pipeline that applies a transform on the target values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A simple example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array(['Alice', 'Bob', 'Charles', 'Dora', 'Eve'])\n",
    "y = np.array(['F', 'M', 'M', 'F', 'F'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline = PipelineY(\n",
    "    steps=[('count', CountVectorizer(analyzer='char')),\n",
    "           ('clf', BernoulliNB())],\n",
    "    y_transformer=LabelEncoder(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PipelineY(steps=[('count', CountVectorizer(analyzer='char', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)), ('clf', BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True))],\n",
       "     y_transformer=LabelEncoder())"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes are the encoded targets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can apply the `y_transform` method to our labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.y_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If supported by the transformer, we may also use the `y_inverse_transform` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True], dtype=bool)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.y_inverse_transform(pipeline.y_transform(y)) == y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The predict method has an optional `inverse` keyword to directly invert the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['F', 'M', 'M', 'F', 'F'], \n",
       "      dtype='<U1')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(X, inverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The PipelineY supports grid search and other facilities that use `get_params` and `set_params`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.random.random(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline = PipelineY(\n",
    "    steps=[('count', CountVectorizer(analyzer='char')),\n",
    "           ('clf', LinearRegression())],\n",
    "    y_transformer=StandardScaler(with_mean=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise',\n",
       "       estimator=PipelineY(steps=[('count', CountVectorizer(analyzer='char', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_word...=1, normalize=False))],\n",
       "     y_transformer=StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'y_transformer__with_mean': [True, False], 'count__max_features': [5, 10], 'clf__fit_intercept': [True, False]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_params = {\n",
    "    'count__max_features': [5, 10],\n",
    "    'clf__fit_intercept': [True, False],\n",
    "    'y_transformer__with_mean': [True, False]\n",
    "}\n",
    "gs = GridSearchCV(pipeline, gs_params, cv=2)\n",
    "gs.fit(X, y.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__fit_intercept': True,\n",
       " 'count__max_features': 10,\n",
       " 'y_transformer__with_mean': False}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SliceMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working extensively with Pipelines or FeatureUnions, accessing `steps` and `transformer_list` can become cumbersome and error prone. For instance, if another transformer is added to the `transformer_list`, one has to pay attention that there are no errors when accessing it by index.\n",
    "\n",
    "`SliceMixin` is a helper mixin class that allows to extend Pipelines and FeatureUnions to allow for more comfortable slicing and indexing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new class that inherits from the mixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SlicePipeline(Pipeline, SliceMixin):\n",
    "    pass\n",
    "\n",
    "class SliceFeatureUnion(FeatureUnion, SliceMixin):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline = SlicePipeline([\n",
    "    ('counts', SliceFeatureUnion([\n",
    "        ('char', CountVectorizer(analyzer='char')),\n",
    "        ('word', CountVectorizer(analyzer='word')),\n",
    "    ])),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', BernoulliNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array(['Alice', 'Bob', 'Charles', 'Dora', 'Eve'])\n",
    "y = np.array([1, 0, 0, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SlicePipeline(steps=[('counts', SliceFeatureUnion(n_jobs=1,\n",
       "         transformer_list=[('char', CountVectorizer(analyzer='char', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngr...se, use_idf=True)), ('clf', BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing steps by name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline['clf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='char', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline['counts']['char']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing steps by index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline[-3][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing steps by slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tfidf',\n",
       "  TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)),\n",
       " ('clf',\n",
       "  BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True))]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the slice creates shallow copies, the estimators returned by the slice are still fitted. This also allows you to quickly create new pipelines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classifier does not support `transform`, therefore this does not work.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    pipeline.transform(X)\n",
    "except AttributeError:\n",
    "    print(\"The classifier does not support `transform`, therefore this does not work.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5x17 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 25 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_transforms = Pipeline(pipeline[:-1])\n",
    "only_transforms.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## DictFeatureUnion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of concatenating the results of a `FeatureUnion` to an array, `FeatureUnionDict` puts them into a dictionary. This could be useful for several applications. For instance, if all values are 1d-arrays, the dictionary can be used to instantiate a `pandas` DataFrame. Furthermore, some libraries such as `tensorflow` or `theano` support feeding data through dictionaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    [0, 10],\n",
    "    [2, 20],\n",
    "]).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformer_list = [\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('polynomialfeatures', PolynomialFeatures()),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "union = DictFeatureUnion(transformer_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xt = union.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The keys of the transformed data, `polynomialfeatures` and `scaler`, correspond to the names indicated in the `transformer_list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'polynomialfeatures': array([[   1.,    0.,   10.,    0.,    0.,  100.],\n",
       "        [   1.,    2.,   20.,    4.,   40.,  400.]]),\n",
       " 'scaler': array([[-1., -1.],\n",
       "        [ 1.,  1.]])}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested `DictFeatureUnion`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "union = DictFeatureUnion([\n",
    "    ('nested', DictFeatureUnion(transformer_list)),\n",
    "    ('another_scaler', StandardScaler()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xt = union.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have 3 keys, 'another_scaler' from the outer `DictFeatureUnion`; 'polynomialfeatures' and 'scaler' from the inner `DictFeatureUnion`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['polynomialfeatures', 'another_scaler', 'scaler'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xt.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrameFeatureUnion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class extends the `FeatureUnion` class to output pandas `DataFrame`s if each transformer outputs a `DataFrame` or `Series`.\n",
    "\n",
    "The index of all outputs must be the same for this to work. Use the parameter `ignore_index` to reset the index of each `DataFrame` before concatenating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame(data={\n",
    "    'names': ['Alice', 'Bob', 'Charles', 'Dora', 'Eve'],\n",
    "    'surnames': ['Carroll', 'Meister', 'Darwin', 'Explorer', 'Wally'],\n",
    "    'age': [14., 30., 55., 7., 25.]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_union = DataFrameFeatureUnion(\n",
    "    transformer_list=[\n",
    "        ('get-first-dataframe', Pipeline([\n",
    "                ('select', ItemSelector('surnames')),\n",
    "            ])\n",
    "         ),\n",
    "        ('get-second-dataframe', Pipeline([\n",
    "                ('select', ItemSelector(['age', 'names'])),\n",
    "            ])\n",
    "         ),\n",
    "    ], ignore_index=True, copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>surnames</th>\n",
       "      <th>age</th>\n",
       "      <th>names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Carroll</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Alice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Meister</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Bob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Darwin</td>\n",
       "      <td>55.0</td>\n",
       "      <td>Charles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Explorer</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Dora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wally</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Eve</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   surnames   age    names\n",
       "0   Carroll  14.0    Alice\n",
       "1   Meister  30.0      Bob\n",
       "2    Darwin  55.0  Charles\n",
       "3  Explorer   7.0     Dora\n",
       "4     Wally  25.0      Eve"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_union.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TimedPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TimedPipeline` is a modified pipeline that helps to quickly check how long each step of a pipeline takes. Getting this information by using tools such as `cProfile` or `line_profiler` is often tedious. `TimedPipeline` is a tool that gives you quick feedback about the timing of each step. Additionally, it will show the output shape after each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = make_classification()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def add1(x):\n",
    "    time.sleep(0.123)\n",
    "    return x + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = TimedPipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('poly', PolynomialFeatures()),\n",
    "    ('pca', PCA(n_components=42)),\n",
    "    ('plus1', FunctionTransformer(add1)),\n",
    "    ('clf', LogisticRegression()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"name\": \"scale\"                       , \"method\": \"fit\"               , \"duration\":        0.000, \"shape\": \"-\"}\n",
      "{\"name\": \"scale\"                       , \"method\": \"transform\"         , \"duration\":        0.000, \"shape\": \"100x20\"}\n",
      "{\"name\": \"scale\"                       , \"method\": \"fit_transform\"     , \"duration\":        0.001, \"shape\": \"100x20\"}\n",
      "{\"name\": \"poly\"                        , \"method\": \"fit\"               , \"duration\":        0.000, \"shape\": \"-\"}\n",
      "{\"name\": \"poly\"                        , \"method\": \"transform\"         , \"duration\":        0.003, \"shape\": \"100x231\"}\n",
      "{\"name\": \"poly\"                        , \"method\": \"fit_transform\"     , \"duration\":        0.003, \"shape\": \"100x231\"}\n",
      "{\"name\": \"pca\"                         , \"method\": \"fit_transform\"     , \"duration\":        0.068, \"shape\": \"100x42\"}\n",
      "{\"name\": \"plus1\"                       , \"method\": \"fit\"               , \"duration\":        0.000, \"shape\": \"-\"}\n",
      "{\"name\": \"plus1\"                       , \"method\": \"transform\"         , \"duration\":        0.123, \"shape\": \"100x42\"}\n",
      "{\"name\": \"plus1\"                       , \"method\": \"fit_transform\"     , \"duration\":        0.124, \"shape\": \"100x42\"}\n",
      "{\"name\": \"clf\"                         , \"method\": \"fit\"               , \"duration\":        0.002, \"shape\": \"-\"}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TimedPipeline(sink=<built-in function print>,\n",
       "       steps=[('scale', StandardScaler(copy=True, with_mean=True, with_std=True)), ('poly', PolynomialFeatures(degree=2, include_bias=True, interaction_only=False)), ('pca', PCA(copy=True, iterated_power='auto', n_components=42, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)), ('plus1', Fun...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"name\": \"scale\"                       , \"method\": \"transform\"         , \"duration\":        0.000, \"shape\": \"100x20\"}\n",
      "{\"name\": \"poly\"                        , \"method\": \"transform\"         , \"duration\":        0.004, \"shape\": \"100x231\"}\n",
      "{\"name\": \"pca\"                         , \"method\": \"transform\"         , \"duration\":        0.000, \"shape\": \"100x42\"}\n",
      "{\"name\": \"plus1\"                       , \"method\": \"transform\"         , \"duration\":        0.123, \"shape\": \"100x42\"}\n",
      "{\"name\": \"clf\"                         , \"method\": \"predict\"           , \"duration\":        0.001, \"shape\": \"100\"}\n"
     ]
    }
   ],
   "source": [
    "_ = pipe.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disable messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to disable messages by calling the `shed_timing` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe.shed_timing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = pipe.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add messages again, call `add_timing`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe.add_timing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"name\": \"scale\"                       , \"method\": \"transform\"         , \"duration\":        0.000, \"shape\": \"100x20\"}\n",
      "{\"name\": \"poly\"                        , \"method\": \"transform\"         , \"duration\":        0.005, \"shape\": \"100x231\"}\n",
      "{\"name\": \"pca\"                         , \"method\": \"transform\"         , \"duration\":        0.000, \"shape\": \"100x42\"}\n",
      "{\"name\": \"plus1\"                       , \"method\": \"transform\"         , \"duration\":        0.123, \"shape\": \"100x42\"}\n",
      "{\"name\": \"clf\"                         , \"method\": \"predict\"           , \"duration\":        0.000, \"shape\": \"100\"}\n"
     ]
    }
   ],
   "source": [
    "_ = pipe.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change sink"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TimedPipeline` has an additional argument, `sink`, that allows to change the target of the messages. The default is `print` but you could, for instance, pass your logger if you want to log the messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = TimedPipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('poly', PolynomialFeatures()),\n",
    "    ('pca', PCA(n_components=42)),\n",
    "    ('plus1', FunctionTransformer(add1)),\n",
    "    ('clf', LogisticRegression()),\n",
    "], sink=partial(print, end=' $\\n\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"name\": \"scale\"                       , \"method\": \"fit\"               , \"duration\":        0.001, \"shape\": \"-\"} $\n",
      "\n",
      "{\"name\": \"scale\"                       , \"method\": \"transform\"         , \"duration\":        0.000, \"shape\": \"100x20\"} $\n",
      "\n",
      "{\"name\": \"scale\"                       , \"method\": \"fit_transform\"     , \"duration\":        0.001, \"shape\": \"100x20\"} $\n",
      "\n",
      "{\"name\": \"poly\"                        , \"method\": \"fit\"               , \"duration\":        0.000, \"shape\": \"-\"} $\n",
      "\n",
      "{\"name\": \"poly\"                        , \"method\": \"transform\"         , \"duration\":        0.003, \"shape\": \"100x231\"} $\n",
      "\n",
      "{\"name\": \"poly\"                        , \"method\": \"fit_transform\"     , \"duration\":        0.004, \"shape\": \"100x231\"} $\n",
      "\n",
      "{\"name\": \"pca\"                         , \"method\": \"fit_transform\"     , \"duration\":        0.006, \"shape\": \"100x42\"} $\n",
      "\n",
      "{\"name\": \"plus1\"                       , \"method\": \"fit\"               , \"duration\":        0.000, \"shape\": \"-\"} $\n",
      "\n",
      "{\"name\": \"plus1\"                       , \"method\": \"transform\"         , \"duration\":        0.123, \"shape\": \"100x42\"} $\n",
      "\n",
      "{\"name\": \"plus1\"                       , \"method\": \"fit_transform\"     , \"duration\":        0.124, \"shape\": \"100x42\"} $\n",
      "\n",
      "{\"name\": \"clf\"                         , \"method\": \"fit\"               , \"duration\":        0.002, \"shape\": \"-\"} $\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TimedPipeline(sink=functools.partial(<built-in function print>, end=' $\\n\\n'),\n",
       "       steps=[('scale', StandardScaler(copy=True, with_mean=True, with_std=True)), ('poly', PolynomialFeatures(degree=2, include_bias=True, interaction_only=False)), ('pca', PCA(copy=True, iterated_power='auto', n_components=42, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)), ('plus1', Fun...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
