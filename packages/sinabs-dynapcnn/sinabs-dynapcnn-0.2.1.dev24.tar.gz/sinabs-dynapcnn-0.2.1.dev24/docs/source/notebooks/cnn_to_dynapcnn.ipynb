{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: From a CNN model to a DYNAP-CNN configuration\n",
    "\n",
    "This tutorial explains all steps necessary to convert a torch CNN model to a configuration of the DYNAP-CNN chip. We will first convert the network to a spiking neural network (SNN) and then to a `DynapcnnCompatibleNetwork` â€“ a model that is compatible with the chip and simulates its behavior. Finally we generate a configuration object that can be used to set up the model on the hardware."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries\n",
    "\n",
    "Before we start, we will import the libraries necessary to define a torch model, convert it to an SNN and to convert the SNN to a `DynapcnnCompatibleNetwork`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Import statements\n",
    "\n",
    "from torch import nn, rand\n",
    "from sinabs.from_torch import from_model\n",
    "from sinabs.backend.dynapcnn import DynapcnnCompatibleNetwork"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN definition\n",
    "\n",
    "First we will define a sequential CNN model. To see what SINABS is capable of, we include elements like Dropout and batch normalization.\n",
    "\n",
    "*Note that although non-sequential models are supported by the hardware, this is not yet the case for this library.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyCNN(\n",
      "  (seq): Sequential(\n",
      "    (0): Conv2d(4, 12, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0)\n",
      "    (3): Conv2d(12, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "    (6): AvgPool2d(kernel_size=(4, 4), stride=(4, 4), padding=0)\n",
      "    (7): Dropout2d(p=0.5, inplace=False)\n",
      "    (8): Flatten()\n",
      "    (9): Linear(in_features=784, out_features=32, bias=False)\n",
      "    (10): ReLU()\n",
      "    (11): Linear(in_features=32, out_features=1, bias=True)\n",
      "    (12): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# - Define CNN model\n",
    "\n",
    "class MyCNN(nn.Module):\n",
    "    def __init__(self, n_channels_in=4, n_channels_out=1):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        seq = [\n",
    "            # Convolutional layer with padding and bias\n",
    "            nn.Conv2d(\n",
    "                in_channels=n_channels_in,\n",
    "                out_channels=12,\n",
    "                kernel_size=(4,4),\n",
    "                padding=(1,1),\n",
    "                bias=True,\n",
    "            ),\n",
    "            # ReLU\n",
    "            nn.ReLU(),\n",
    "            # Average pooling (stride equal to kernel size)\n",
    "            nn.AvgPool2d(kernel_size=(2,2), stride=(2,2)),\n",
    "            # Convolutional layer and batch normalization\n",
    "            nn.Conv2d(\n",
    "                in_channels=12,\n",
    "                out_channels=16,\n",
    "                kernel_size=(3,3),\n",
    "                bias=True,\n",
    "            ),\n",
    "            nn.BatchNorm2d(num_features=16),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(kernel_size=(4,4), stride=(4,4)),\n",
    "            # Dropout\n",
    "            nn.Dropout2d(0.5),\n",
    "            # Two fully connected layers\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(784, 32, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, n_channels_out, bias=True),\n",
    "            nn.ReLU(),\n",
    "        ]\n",
    "        self.seq = nn.Sequential(*seq)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.seq(x)\n",
    "    \n",
    "cnn = MyCNN()\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to Spiking CNN\n",
    "\n",
    "We can use the `from_torch` method from SINABS to convert our CNN to a SNN. The returned object contains the original CNN as `analog_model` and the newly generated SNN as `spiking_model`. The `ReLU`s have been converted to `SpikingLayers`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyCNN(\n",
      "  (seq): Sequential(\n",
      "    (0): Conv2d(4, 12, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "    (1): SpikingLayer()\n",
      "    (2): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0)\n",
      "    (3): Conv2d(12, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): SpikingLayer()\n",
      "    (6): AvgPool2d(kernel_size=(4, 4), stride=(4, 4), padding=0)\n",
      "    (7): Dropout2d(p=0.5, inplace=False)\n",
      "    (8): Flatten()\n",
      "    (9): Linear(in_features=784, out_features=32, bias=False)\n",
      "    (10): SpikingLayer()\n",
      "    (11): Linear(in_features=32, out_features=1, bias=True)\n",
      "    (12): SpikingLayer()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "snn = from_model(cnn)\n",
    "print(snn.spiking_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DYNAP-CNN compatible network\n",
    "\n",
    "The next step is to convert the SNN to a `DynapcnnCompatibleNetwork`. This way we can be sure that all functionalities of our network are supported by the hardware and we can simulate the expected hardware output for testing purposes. This object will also generate the configuration objects to set up the chip.\n",
    "\n",
    "We need to tell the chip the dimensions of the input data. This can be done either by specifying an `input_shape` argument in the constructor or including a SINABS `InputLayer` at the beginning of the model.\n",
    "\n",
    "The class will convert the parameters (weights, biases, and thresholds) to discrete values that are supported by DYNAP-CNN. For testing purposes this can be disabled by setting `discretize` to `False`.\n",
    "\n",
    "We can use the `dvs_input` flag to determine whether the chip should process data coming from the on-chip dynamic vision sensor (DVS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DynapcnnCompatibleNetwork(\n",
      "  (sequence): Sequential(\n",
      "    (0): DynapcnnLayer(\n",
      "      (_conv_layer): Conv2d(4, 12, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "      (_pool_layer): SumPool2d(norm_type=1, kernel_size=2, stride=2, ceil_mode=False)\n",
      "      (_spk_layer): SpikingLayer()\n",
      "    )\n",
      "    (1): DynapcnnLayer(\n",
      "      (_conv_layer): Conv2d(12, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (_pool_layer): SumPool2d(norm_type=1, kernel_size=4, stride=4, ceil_mode=False)\n",
      "      (_spk_layer): SpikingLayer()\n",
      "    )\n",
      "    (2): DynapcnnLayer(\n",
      "      (_conv_layer): Conv2d(16, 32, kernel_size=(7, 7), stride=(1, 1), bias=False)\n",
      "      (_spk_layer): SpikingLayer()\n",
      "    )\n",
      "    (3): DynapcnnLayer(\n",
      "      (_conv_layer): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (_spk_layer): SpikingLayer()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# - Input dimensions\n",
    "input_shape = (4, 64, 64)\n",
    "\n",
    "# - DYNAP-CNN compatible network\n",
    "dynapcnn_net = DynapcnnCompatibleNetwork(\n",
    "    snn,\n",
    "    input_shape=input_shape,\n",
    "    discretize=False,\n",
    "    dvs_input=True,\n",
    ")\n",
    "print(dynapcnn_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting model consists of four `DynapcnnLayer` objects, each containing a convolutional, a spiking, and possibly a pooling layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[9.]]]])\n"
     ]
    }
   ],
   "source": [
    "# - Run network on random data\n",
    "input_data = rand((1, *input_shape)) * 1000\n",
    "output_data = dynapcnn_net(input_data)\n",
    "\n",
    "# - Model is quantized, so the output will have an integer value.\n",
    "print(output_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DYNAP-CNN configuration\n",
    "\n",
    "We can now extract a dynapcnn configuration object from the `DynapcnnCompatibleNetwork`, which can then be used to configure the hardware. In order to map layers of the sequential model to specific layers on the chip we can provide a list of layer indices in the order of the data flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dynapcnn_net.make_config(dynapcnn_layers_ordering=[4, 2, 1, 7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation and upload to DYNAP-CNN\n",
    "\n",
    "Finally, we only need to upload the configuration to the hardware. Before that however, it should be made sure that the way the layers are arranged is compatible.\n",
    "\n",
    "The functionalities for validation and uploading will soon be added and explained here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
