# This package will contain the spiders of your Scrapy project
#
# Please refer to the documentation for information on how to create and manage
# your spiders.

import scrapy

from lich_scrapy_hdfs_pipeline.items import ExampleItem


class ExampleSpider(scrapy.Spider):
    """ ExampleSpider
    Auto generated by os-scrapy-cookiecuter

    Run:
        scrapy crawl example
    """

    name = "example"

    def start_requests(self):
        yield scrapy.Request(
            # url="https://upload.wikimedia.org/wikipedia/commons/0/03/Joe_Biden_2013.jpg",
            url="http://example.com/",
            meta={
                "hdfs.env": "diablo",
                "hdfs.saver_type": "httpzip",
                "hdfs.stores": [
                    {
                        "kafka.topic": "lich_test_topic",
                        "kafka.cluster": "KafkaHB",
                        "kafka.brokers": "kafka001.wd.hb.ted:9092,kafka002.wd.hb.ted:9092",
                    }
                ],
            },
        )

    def parse(self, response):
        request = response.request
        yield ExampleItem(
            request={
                "url": request.url,
                "method": request.method,
                "headers": request.headers,
                "body": request.body,
            },
            response={
                "status": response.status,
                "headers": response.headers,
                "body": response.body,
            },
            meta=response.meta,
        )
