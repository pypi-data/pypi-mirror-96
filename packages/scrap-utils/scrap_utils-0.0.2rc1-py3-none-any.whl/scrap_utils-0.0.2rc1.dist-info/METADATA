Metadata-Version: 2.1
Name: scrap-utils
Version: 0.0.2rc1
Summary: A small package that contains commonly used codes while scraping
Home-page: https://github.com/bizzyvinci/scrap-utils
Author: Bisola Olasehinde
Author-email: horlasehinde@gmail.com
License: MIT
Keywords: scrap,scraping,scraper,requests,csv,json
Platform: UNKNOWN
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.6
Description-Content-Type: text/markdown
Requires-Dist: requests

# Scrap Utils
This is small package that contains some code regularly repeated when scraping.

### To install
```python
pip install scrap-utils
```

### To import in your program
```python
import scrap_utils
```


### It has the following functions:
```python
load_json(filepath, encoding=None, errors=None, parse_float=None,
	parse_int=None, parse_constant=None)

dump_json(data, filepath, encoding=None, errors=None, indent=4, skipkeys=False,
	ensure_ascii=False, separators=None, sort_keys=False)

to_csv(dataset, filepath, mode="a", encoding=None, errors=None, newline='',
	header=True, dialect='excel', **fmtparams)

requests_get(url, trials=0, sleep_time=30, max_try=math.inf, **requests_kwargs)

requests_post(url, trials=0, sleep_time=30, max_try=math.inf, **requests_kwargs)
```

### To-do list I'm considering:
* remove print statements
* add unittest
* soup_get()
* driver_get()
* start_firefox()
* read_csv()

#### Feel free to add your contribution [here](https://github.com/bizzyvinci/scrap-utils)

